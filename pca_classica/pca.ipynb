{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PCA Clássica para classificar banco de dados iris.dat\n",
    "\n",
    "<div style=\"text-align: right\">Exercício de sala<br>Felipe Tassario Gomes - N. USP 5396784<br>Vitor Boschi</div>\n",
    "\n",
    "O banco de dados iris.dat foi um conjunto de dados publicado em 1936, contendo um conjunto de observações sobre 4 característiscas diferentes do gênero de flores *Iris*. Essas características foram medidas para 150 amostras, divididas igualmente entre 3 espécies de flor: *Iris setosa*, *Iris virginica* e *Iris versicolor*.\n",
    "As 4 características são:\n",
    "1. comprimento da sépala\n",
    "2. largura da sépala\n",
    "3. comprimento da pétala\n",
    "4. largura da pétala\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ler dados\n",
    "Primeiramente vamos importar as bibliotecas necessárias e ler o arquivos de dados iris.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from pybrain.tools.shortcuts import *\n",
    "from pybrain.datasets import *\n",
    "from pybrain.supervised.trainers import *\n",
    "from pybrain.structure.modules import *\n",
    "\n",
    "from matplotlib.pyplot import *\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 150 entries in the dataset\n"
     ]
    }
   ],
   "source": [
    "training_file = open('iris.data','r')\n",
    "\n",
    "input_array = []\n",
    "output_array = []\n",
    "\n",
    "for x in training_file.readlines():\n",
    "    if (x.strip() == ''):\n",
    "        continue\n",
    "\n",
    "    line = x.strip().split(',')\n",
    "    \n",
    "    \n",
    "    this_input = [float(num) for num in line[:-1]]\n",
    "    \n",
    "    output_name = line[-1]\n",
    "    name_map = {\n",
    "        \"Iris-setosa\": 0,\n",
    "        \"Iris-versicolor\": 1,\n",
    "        \"Iris-virginica\": 2\n",
    "    }\n",
    "    this_output = name_map.get(output_name) #output value\n",
    "    \n",
    "    input_array.append(this_input)\n",
    "    output_array.append(this_output)\n",
    "    \n",
    "    #print \"Added entry: \", this_input, \" => \", output_name, \"(%d)\" % this_output\n",
    "\n",
    "print \"Added %d entries in the dataset\" % len(input_array)\n",
    "\n",
    "assert(len(input_array) == len(output_array))\n",
    "#    DS.addSample(inputs, output_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([50, 50, 50]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_info = np.unique(output_array, return_counts=True)\n",
    "unique_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_array = np.array(input_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização\n",
    "\n",
    "Normalização para distribuição Gaussiana, mean=0 and variance=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Primeiro transformamos nossa coluna de entrada numa estrada de array do numpy\n",
    "normalized_input = np.array(input_array)\n",
    "\n",
    "# Agora dividimos cada elemento da matriz pelo maior valor em sua coluna,\n",
    "# normalizando assim as 4 propriedades na entrada.\n",
    "normalized_input = normalized_input - normalized_input.mean(axis=0)\n",
    "normalized_input = normalized_input / normalized_input.std(axis=0)\n",
    "assert(normalized_input.shape == (150, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de covariância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0067, -0.1101,  0.8776,  0.8234],\n",
       "       [-0.1101,  1.0067, -0.4233, -0.3589],\n",
       "       [ 0.8776, -0.4233,  1.0067,  0.9692],\n",
       "       [ 0.8234, -0.3589,  0.9692,  1.0067]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_cov = np.cov(normalized_input.T)\n",
    "norm_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Auto-valores e auto-vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.9304,  0.9274,  0.1483,  0.0207]),\n",
       " array([[ 0.5224, -0.3723, -0.721 ,  0.262 ],\n",
       "        [-0.2634, -0.9256,  0.242 , -0.1241],\n",
       "        [ 0.5813, -0.0211,  0.1409, -0.8012],\n",
       "        [ 0.5656, -0.0654,  0.6338,  0.5235]]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig = np.linalg.eig(norm_cov)\n",
    "eig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7277,  0.2303,  0.0368,  0.0052])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals = eig[0]\n",
    "\n",
    "# The documentation of np.linalg.eig says:\n",
    "# - The normalized (unit “length”) eigenvectors, such that the column\n",
    "# - v[:,i] is the eigenvector corresponding to the eigenvalue w[i].\n",
    "#\n",
    "# This means that the eigenvectors are transposed\n",
    "\n",
    "eigvecs = eig[1].T\n",
    "\n",
    "#contribuicoes de cada dimensao\n",
    "contribs = eigvals / eigvals.sum()\n",
    "contribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(eigvecs)):\n",
    "    print np.linalg.norm(eigvecs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 dimensao: 72.77%\n",
      "2 dimensao: 95.80%\n",
      "3 dimensao: 99.48%\n",
      "4 dimensao: 100.00%\n"
     ]
    }
   ],
   "source": [
    "#contribuicoes cumulativas\n",
    "acumulado = 0\n",
    "for i in range(len(contribs)):\n",
    "    acumulado += contribs[i]\n",
    "    print \"%d dimensao: %.2f%%\" % (i + 1, acumulado * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.2645, -0.5057],\n",
       "       [-2.0864,  0.6554],\n",
       "       [-2.368 ,  0.3185],\n",
       "       [-2.3042,  0.5754],\n",
       "       [-2.3888, -0.6748],\n",
       "       [-2.0705, -1.5185],\n",
       "       [-2.4457, -0.0746],\n",
       "       [-2.2338, -0.2476],\n",
       "       [-2.342 ,  1.0951],\n",
       "       [-2.1887,  0.4486],\n",
       "       [-2.1635, -1.0706],\n",
       "       [-2.3274, -0.1586],\n",
       "       [-2.2241,  0.7091],\n",
       "       [-2.6397,  0.9383],\n",
       "       [-2.1923, -1.89  ],\n",
       "       [-2.2515, -2.7224],\n",
       "       [-2.2028, -1.5138],\n",
       "       [-2.1902, -0.5143],\n",
       "       [-1.8941, -1.4311],\n",
       "       [-2.3399, -1.158 ],\n",
       "       [-1.9146, -0.4305],\n",
       "       [-2.2046, -0.9525],\n",
       "       [-2.7742, -0.4895],\n",
       "       [-1.8204, -0.1068],\n",
       "       [-2.2282, -0.1622],\n",
       "       [-1.957 ,  0.6079],\n",
       "       [-2.0521, -0.266 ],\n",
       "       [-2.1682, -0.552 ],\n",
       "       [-2.1403, -0.3366],\n",
       "       [-2.2688,  0.3149],\n",
       "       [-2.1446,  0.4839],\n",
       "       [-1.8319, -0.4453],\n",
       "       [-2.6082, -1.8285],\n",
       "       [-2.438 , -2.1854],\n",
       "       [-2.1887,  0.4486],\n",
       "       [-2.2111,  0.1843],\n",
       "       [-2.0444, -0.685 ],\n",
       "       [-2.1887,  0.4486],\n",
       "       [-2.436 ,  0.8822],\n",
       "       [-2.1705, -0.2927],\n",
       "       [-2.2865, -0.468 ],\n",
       "       [-1.8717,  2.3277],\n",
       "       [-2.5578,  0.4538],\n",
       "       [-1.9643, -0.4974],\n",
       "       [-2.1334, -1.1714],\n",
       "       [-2.0754,  0.6919],\n",
       "       [-2.3813, -1.1506],\n",
       "       [-2.3982,  0.3624],\n",
       "       [-2.2268, -1.0255],\n",
       "       [-2.206 , -0.0322],\n",
       "       [ 1.104 , -0.8631],\n",
       "       [ 0.7325, -0.5986],\n",
       "       [ 1.2421, -0.6148],\n",
       "       [ 0.3973,  1.7582],\n",
       "       [ 1.0726,  0.2118],\n",
       "       [ 0.3845,  0.5911],\n",
       "       [ 0.7487, -0.7787],\n",
       "       [-0.4979,  1.8489],\n",
       "       [ 0.9262, -0.0303],\n",
       "       [ 0.005 ,  1.0294],\n",
       "       [-0.1247,  2.6581],\n",
       "       [ 0.4387,  0.0589],\n",
       "       [ 0.5516,  1.7726],\n",
       "       [ 0.7172,  0.1854],\n",
       "       [-0.0373,  0.4328],\n",
       "       [ 0.8759, -0.51  ],\n",
       "       [ 0.348 ,  0.1906],\n",
       "       [ 0.1534,  0.7907],\n",
       "       [ 1.2153,  1.6334],\n",
       "       [ 0.1569,  1.3031],\n",
       "       [ 0.7383, -0.4025],\n",
       "       [ 0.4724,  0.4166],\n",
       "       [ 1.228 ,  0.9409],\n",
       "       [ 0.6294,  0.4168],\n",
       "       [ 0.7005,  0.0635],\n",
       "       [ 0.8735, -0.2507],\n",
       "       [ 1.2542,  0.0826],\n",
       "       [ 1.3582, -0.3288],\n",
       "       [ 0.6621,  0.2243],\n",
       "       [-0.0473,  1.0572],\n",
       "       [ 0.1215,  1.5636],\n",
       "       [ 0.0141,  1.5734],\n",
       "       [ 0.236 ,  0.7759],\n",
       "       [ 1.0567,  0.6369],\n",
       "       [ 0.2214,  0.2808],\n",
       "       [ 0.4318, -0.8551],\n",
       "       [ 1.0494, -0.5222],\n",
       "       [ 1.0359,  1.3925],\n",
       "       [ 0.0671,  0.2126],\n",
       "       [ 0.2754,  1.3298],\n",
       "       [ 0.2723,  1.1194],\n",
       "       [ 0.6232, -0.0275],\n",
       "       [ 0.33  ,  0.9889],\n",
       "       [-0.3736,  2.0179],\n",
       "       [ 0.2829,  0.854 ],\n",
       "       [ 0.0891,  0.1749],\n",
       "       [ 0.2244,  0.3805],\n",
       "       [ 0.5739,  0.1537],\n",
       "       [-0.457 ,  1.5395],\n",
       "       [ 0.2522,  0.5959],\n",
       "       [ 1.8477, -0.8717],\n",
       "       [ 1.1532,  0.7013],\n",
       "       [ 2.2063, -0.5545],\n",
       "       [ 1.4387,  0.05  ],\n",
       "       [ 1.8679, -0.2912],\n",
       "       [ 2.7542, -0.7884],\n",
       "       [ 0.3584,  1.5601],\n",
       "       [ 2.303 , -0.4095],\n",
       "       [ 2.0017,  0.7239],\n",
       "       [ 2.2676, -1.9214],\n",
       "       [ 1.3659, -0.6939],\n",
       "       [ 1.5991,  0.4282],\n",
       "       [ 1.8843, -0.4143],\n",
       "       [ 1.2531,  1.1674],\n",
       "       [ 1.4641,  0.4441],\n",
       "       [ 1.5918, -0.677 ],\n",
       "       [ 1.4713, -0.2532],\n",
       "       [ 2.4374, -2.5568],\n",
       "       [ 3.3091,  0.0024],\n",
       "       [ 1.254 ,  1.7176],\n",
       "       [ 2.0405, -0.9074],\n",
       "       [ 0.9739,  0.5712],\n",
       "       [ 2.8981, -0.3978],\n",
       "       [ 1.3292,  0.4868],\n",
       "       [ 1.7042, -1.0141],\n",
       "       [ 1.9577, -1.0033],\n",
       "       [ 1.1719,  0.3189],\n",
       "       [ 1.0198, -0.0655],\n",
       "       [ 1.786 ,  0.1933],\n",
       "       [ 1.8648, -0.5554],\n",
       "       [ 2.4355, -0.2467],\n",
       "       [ 2.3161, -2.6262],\n",
       "       [ 1.8604,  0.1847],\n",
       "       [ 1.1113,  0.296 ],\n",
       "       [ 1.1975,  0.8172],\n",
       "       [ 2.8009, -0.8447],\n",
       "       [ 1.5802, -1.0725],\n",
       "       [ 1.347 , -0.4223],\n",
       "       [ 0.9234, -0.0192],\n",
       "       [ 1.8536, -0.6724],\n",
       "       [ 2.0162, -0.6104],\n",
       "       [ 1.9031, -0.686 ],\n",
       "       [ 1.1532,  0.7013],\n",
       "       [ 2.0433, -0.8647],\n",
       "       [ 2.0017, -1.0486],\n",
       "       [ 1.8705, -0.3828],\n",
       "       [ 1.5585,  0.9053],\n",
       "       [ 1.5208, -0.2668],\n",
       "       [ 1.3764, -1.0164],\n",
       "       [ 0.9593,  0.0223]])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs_to_use = 2\n",
    "\n",
    "new_input = np.ndarray((len(input_array), vecs_to_use))\n",
    "new_input.shape\n",
    "\n",
    "for i in range(len(input_array)):\n",
    "    for j in range(vecs_to_use):\n",
    "        new_input[i][j] = normalized_input[i].dot(eigvecs[j])\n",
    "\n",
    "new_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues in descending order:\n",
      "2.93035377559\n",
      "0.927403621517\n",
      "0.148342226482\n",
      "0.0207460139956\n"
     ]
    }
   ],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(norm_cov)\n",
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort()\n",
    "eig_pairs.reverse()\n",
    "\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "print('Eigenvalues in descending order:')\n",
    "for i in eig_pairs:\n",
    "    print(i[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3723 -0.9256 -0.0211 -0.0654]\n",
      "[-0.3723 -0.9256 -0.0211 -0.0654]\n"
     ]
    }
   ],
   "source": [
    "print(eigvecs[])\n",
    "print(eig_pairs[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5224, -0.2634,  0.5813,  0.5656])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_vecs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5224, -0.3723],\n",
       "       [-0.2634, -0.9256],\n",
       "       [ 0.5813, -0.0211],\n",
       "       [ 0.5656, -0.0654]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_w = np.hstack((eigvecs[0].reshape(4,1),\n",
    "                      eigvecs[1].reshape(4,1)))\n",
    "matrix_w\n",
    "\n",
    "\n",
    "\n",
    "#matrix_w = np.hstack((eig_pairs[0][1].reshape(4,1),\n",
    " #                     eig_pairs[1][1].reshape(4,1)))\n",
    "\n",
    "Y = normalized_input.dot(matrix_w)\n",
    "matrix_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exibindo resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEACAYAAACqOy3+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wGxvRv9N2Kq/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c0fd790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figures = [\n",
    "    \"ro\",  #red circle\n",
    "    \"bo\",  #blue circle\n",
    "    \"gx\"   #green X\n",
    "    ]\n",
    "\n",
    "figure(1)\n",
    "#xlim(-1, 1)\n",
    "#ylim(-1, 1)\n",
    "for i in range(len(input_array)):\n",
    "    point = new_input[i]\n",
    "    plot(point[0], point[1], figures[output_array[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Adaptativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_entradas = 4\n",
    "N_saidas = 2\n",
    "\n",
    "W =  (np.random.rand(N_entradas, N_saidas))/2\n",
    "U =  np.zeros((N_saidas, N_saidas))\n",
    "\n",
    "#gera uma saida\n",
    "def apresentar_entrada(input):\n",
    "    saida = np.zeros(N_saidas)\n",
    "    \n",
    "    for j in range(N_saidas):\n",
    "        for i in range(N_entradas):\n",
    "            saida[j] += W[i][j] * input[i]\n",
    "\n",
    "    for i in range(N_saidas):\n",
    "        for j in range(N_saidas):\n",
    "            if i >= j:\n",
    "                continue\n",
    "            \n",
    "            saida[j] += U[i][j] * saida[i]\n",
    "            \n",
    "    return saida\n",
    "\n",
    "def atualizar_W(input, saida, neta):\n",
    "    for i in range(N_entradas):\n",
    "        for j in range(N_saidas):\n",
    "            delta = neta * input[i] * saida[j]\n",
    "            W[i][j] += delta\n",
    "            \n",
    "def atualizar_J(saida, mu):\n",
    "    for i in range(N_saidas):\n",
    "        for j in range(N_saidas):\n",
    "            if i >= j:\n",
    "                continue\n",
    "                \n",
    "            delta = - mu * saida[i] * saida[j]\n",
    "            U[i][j] += delta\n",
    "\n",
    "def normalizar_W():\n",
    "    return W / W.max(axis=0)\n",
    "    \n",
    "\n",
    "def neta(epoch_num):\n",
    "    return 0.1 / epoch_num\n",
    "    \n",
    "def run_epoch(db, epoch_num):\n",
    "    inputs = np.random.permutation(db)\n",
    "    \n",
    "    saida_total = np.ndarray((len(input_array), N_saidas))\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        saida = apresentar_entrada(inputs[i])\n",
    "        atualizar_W(inputs[i], saida, neta(epoch_num))\n",
    "        W = normalizar_W()\n",
    "        atualizar_J(saida, neta(epoch_num))\n",
    "        saida_total[i] = saida\n",
    "        \n",
    "    return saida_total\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = np.random.permutation(normalized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saida [-0.165 -0.321]\n",
      "W [[ 0.0223  0.356 ]\n",
      " [ 0.1133  0.1437]\n",
      " [ 0.2123  0.2512]\n",
      " [ 0.0916  0.1805]]\n",
      "U [[ 0.      0.    ]\n",
      " [-0.0005  0.    ]]\n",
      "atualizado\n",
      "W [[ 0.0226  0.3566]\n",
      " [ 0.1105  0.1382]\n",
      " [ 0.2142  0.255 ]\n",
      " [ 0.0936  0.1843]]\n",
      "U [[ 0.     0.   ]\n",
      " [-0.001  0.   ]]\n",
      "normalizado\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.1054,  1.    ],\n",
       "       [ 0.5157,  0.3875],\n",
       "       [ 1.    ,  0.715 ],\n",
       "       [ 0.4368,  0.5168]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = inputs[0]\n",
    "saida = apresentar_entrada(inp)\n",
    "\n",
    "print \"saida\", saida\n",
    "print \"W\", W\n",
    "print \"U\", U\n",
    "\n",
    "atualizar_W(inp, saida, 0.01)\n",
    "atualizar_J(saida, 0.01)\n",
    "\n",
    "print \"atualizado\"\n",
    "print \"W\", W\n",
    "print \"U\", U\n",
    "\n",
    "print \"normalizado\"\n",
    "normalizar_W()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 0\n",
      "running 1\n",
      "running 2\n",
      "running 3\n",
      "running 4\n",
      "running 5\n",
      "running 6\n",
      "running 7\n",
      "running 8\n",
      "running 9\n",
      "running 10\n",
      "running 11\n",
      "running 12\n",
      "running 13\n",
      "running 14\n",
      "running 15\n",
      "running 16\n",
      "running 17\n",
      "running 18\n",
      "running 19\n",
      "running 20\n",
      "running 21\n",
      "running 22\n",
      "running 23\n",
      "running 24\n",
      "running 25\n",
      "running 26\n",
      "running 27\n",
      "running 28\n",
      "running 29\n",
      "running 30\n",
      "running 31\n",
      "running 32\n",
      "running 33\n",
      "running 34\n",
      "running 35\n",
      "running 36\n",
      "running 37\n",
      "running 38\n",
      "running 39\n",
      "running 40\n",
      "running 41\n",
      "running 42\n",
      "running 43\n",
      "running 44\n",
      "running 45\n",
      "running 46\n",
      "running 47\n",
      "running 48\n",
      "running 49\n",
      "running 50\n",
      "running 51\n",
      "running 52\n",
      "running 53\n",
      "running 54\n",
      "running 55\n",
      "running 56\n",
      "running 57\n",
      "running 58\n",
      "running 59\n",
      "running 60\n",
      "running 61\n",
      "running 62\n",
      "running 63\n",
      "running 64\n",
      "running 65\n",
      "running 66\n",
      "running 67\n",
      "running 68\n",
      "running 69\n",
      "running 70\n",
      "running 71\n",
      "running 72\n",
      "running 73\n",
      "running 74\n",
      "running 75\n",
      "running 76\n",
      "running 77\n",
      "running 78\n",
      "running 79\n",
      "running 80\n",
      "running 81\n",
      "running 82\n",
      "running 83\n",
      "running 84\n",
      "running 85\n",
      "running 86\n",
      "running 87\n",
      "running 88\n",
      "running 89\n",
      "running 90\n",
      "running 91\n",
      "running 92\n",
      "running 93\n",
      "running 94\n",
      "running 95\n",
      "running 96\n",
      "running 97\n",
      "running 98\n",
      "running 99\n",
      "running 100\n",
      "running 101\n",
      "running 102\n",
      "running 103\n",
      "running 104\n",
      "running 105\n",
      "running 106\n",
      "running 107\n",
      "running 108\n",
      "running 109\n",
      "running 110\n",
      "running 111\n",
      "running 112\n",
      "running 113\n",
      "running 114\n",
      "running 115\n",
      "running 116\n",
      "running 117\n",
      "running 118\n",
      "running 119\n",
      "running 120\n",
      "running 121\n",
      "running 122\n",
      "running 123\n",
      "running 124\n",
      "running 125\n",
      "running 126\n",
      "running 127\n",
      "running 128\n",
      "running 129\n",
      "running 130\n",
      "running 131\n",
      "running 132\n",
      "running 133\n",
      "running 134\n",
      "running 135\n",
      "running 136\n",
      "running 137\n",
      "running 138\n",
      "running 139\n",
      "running 140\n",
      "running 141\n",
      "running 142\n",
      "running 143\n",
      "running 144\n",
      "running 145\n",
      "running 146\n",
      "running 147\n",
      "running 148\n",
      "running 149\n",
      "running 150\n",
      "running 151\n",
      "running 152\n",
      "running 153\n",
      "running 154\n",
      "running 155\n",
      "running 156\n",
      "running 157\n",
      "running 158\n",
      "running 159\n",
      "running 160\n",
      "running 161\n",
      "running 162\n",
      "running 163\n",
      "running 164\n",
      "running 165\n",
      "running 166\n",
      "running 167\n",
      "running 168\n",
      "running 169\n",
      "running 170\n",
      "running 171\n",
      "running 172\n",
      "running 173\n",
      "running 174\n",
      "running 175\n",
      "running 176\n",
      "running 177\n",
      "running 178\n",
      "running 179\n",
      "running 180\n",
      "running 181\n",
      "running 182\n",
      "running 183\n",
      "running 184\n",
      "running 185\n",
      "running 186\n",
      "running 187\n",
      "running 188\n",
      "running 189\n",
      "running 190\n",
      "running 191\n",
      "running 192\n",
      "running 193\n",
      "running 194\n",
      "running 195\n",
      "running 196\n",
      "running 197\n",
      "running 198\n",
      "running 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:36: RuntimeWarning: overflow encountered in double_scalars\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:40: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:37: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    print \"running\", i\n",
    "    run_epoch(normalized_input, i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 50, 1: 50, 2: 50}"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_dataset(input, target):\n",
    "    DS = ClassificationDataSet(len(input[0]), class_labels=['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])\n",
    "    for i in range(0, len(input)):\n",
    "        DS.addSample(input[i], target[i])\n",
    "    return DS\n",
    "\n",
    "DS = generate_dataset(new_input, output_array)\n",
    "\n",
    "# Verificar que os dados estão como esperado\n",
    "DS.calculateStatistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.2421, -0.6148])"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS.getField(\"input\")[52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DS._convertToOneOfMany()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS.outdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS.getField(\"target\")[52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino: 112, Teste: 38\n"
     ]
    }
   ],
   "source": [
    "TrainDS, TestDS = DS.splitWithProportion(0.75)\n",
    "\n",
    "print \"Treino: %d, Teste: %d\" % (len(TrainDS), len(TestDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def criar_rede(dataset, learningrate=0.5):\n",
    "    # Criando a rede neural\n",
    "    network = buildNetwork(dataset.indim, 5, dataset.outdim, bias=True, outclass = SoftmaxLayer)\n",
    "    \n",
    "    # Criando o objeto \"trainer\" da rede neural\n",
    "    trainer = BackpropTrainer(network, dataset, learningrate)\n",
    "    return network, trainer\n",
    "\n",
    "network, trainer = criar_rede(TrainDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progresso: treinos: 20, erro: 0.017904\n",
      "Progresso: treinos: 40, erro: 0.023471\n",
      "Progresso: treinos: 60, erro: 0.019587\n",
      "Progresso: treinos: 80, erro: 0.020345\n",
      "Progresso: treinos: 100, erro: 0.017501\n",
      "Progresso: treinos: 120, erro: 0.017841\n",
      "Progresso: treinos: 140, erro: 0.017721\n",
      "Progresso: treinos: 160, erro: 0.019492\n",
      "Progresso: treinos: 180, erro: 0.018176\n",
      "Progresso: treinos: 200, erro: 0.018063\n",
      "Progresso: treinos: 220, erro: 0.019122\n",
      "Progresso: treinos: 240, erro: 0.019132\n",
      "Progresso: treinos: 260, erro: 0.018254\n",
      "Progresso: treinos: 280, erro: 0.018815\n",
      "Progresso: treinos: 300, erro: 0.016792\n",
      "Progresso: treinos: 320, erro: 0.016209\n",
      "Progresso: treinos: 340, erro: 0.017545\n",
      "Progresso: treinos: 360, erro: 0.015414\n",
      "Progresso: treinos: 380, erro: 0.015826\n",
      "Progresso: treinos: 400, erro: 0.014317\n",
      "Progresso: treinos: 420, erro: 0.017860\n",
      "Progresso: treinos: 440, erro: 0.016200\n",
      "Progresso: treinos: 460, erro: 0.016860\n",
      "Progresso: treinos: 480, erro: 0.017776\n",
      "Progresso: treinos: 500, erro: 0.016738\n",
      "Progresso: treinos: 520, erro: 0.015605\n",
      "Progresso: treinos: 540, erro: 0.016647\n",
      "Progresso: treinos: 560, erro: 0.017622\n",
      "Progresso: treinos: 580, erro: 0.016221\n",
      "Progresso: treinos: 600, erro: 0.015989\n",
      "Progresso: treinos: 620, erro: 0.017073\n",
      "Progresso: treinos: 640, erro: 0.018619\n",
      "Progresso: treinos: 660, erro: 0.017586\n",
      "Progresso: treinos: 680, erro: 0.015908\n",
      "Progresso: treinos: 700, erro: 0.017438\n",
      "Progresso: treinos: 720, erro: 0.016257\n",
      "Progresso: treinos: 740, erro: 0.016176\n",
      "Progresso: treinos: 760, erro: 0.013803\n",
      "Progresso: treinos: 780, erro: 0.015167\n",
      "Progresso: treinos: 800, erro: 0.016415\n",
      "Progresso: treinos: 820, erro: 0.016895\n",
      "Progresso: treinos: 840, erro: 0.016857\n",
      "Progresso: treinos: 860, erro: 0.013813\n",
      "Progresso: treinos: 880, erro: 0.015950\n",
      "Progresso: treinos: 900, erro: 0.017562\n",
      "Progresso: treinos: 920, erro: 0.016869\n",
      "Progresso: treinos: 940, erro: 0.015267\n",
      "Progresso: treinos: 960, erro: 0.016557\n",
      "Progresso: treinos: 980, erro: 0.016912\n",
      "Progresso: treinos: 1000, erro: 0.017050\n",
      "Progresso: treinos: 1020, erro: 0.015408\n",
      "Progresso: treinos: 1040, erro: 0.017308\n",
      "Progresso: treinos: 1060, erro: 0.016620\n",
      "Progresso: treinos: 1080, erro: 0.014766\n",
      "Progresso: treinos: 1100, erro: 0.016583\n",
      "Progresso: treinos: 1120, erro: 0.017467\n",
      "Progresso: treinos: 1140, erro: 0.016033\n",
      "Progresso: treinos: 1160, erro: 0.016561\n",
      "Progresso: treinos: 1180, erro: 0.014982\n",
      "Progresso: treinos: 1200, erro: 0.015961\n",
      "Progresso: treinos: 1220, erro: 0.017307\n",
      "Progresso: treinos: 1240, erro: 0.015981\n",
      "Progresso: treinos: 1260, erro: 0.016931\n",
      "Progresso: treinos: 1280, erro: 0.017262\n",
      "Progresso: treinos: 1300, erro: 0.016735\n",
      "Progresso: treinos: 1320, erro: 0.016968\n",
      "Progresso: treinos: 1340, erro: 0.015070\n",
      "Progresso: treinos: 1360, erro: 0.014471\n",
      "Progresso: treinos: 1380, erro: 0.017490\n",
      "Progresso: treinos: 1400, erro: 0.016085\n",
      "Progresso: treinos: 1420, erro: 0.015583\n",
      "Progresso: treinos: 1440, erro: 0.017283\n",
      "Progresso: treinos: 1460, erro: 0.015206\n",
      "Progresso: treinos: 1480, erro: 0.017309\n",
      "Progresso: treinos: 1500, erro: 0.016281\n",
      "Progresso: treinos: 1520, erro: 0.012030\n",
      "Progresso: treinos: 1540, erro: 0.016918\n",
      "Progresso: treinos: 1560, erro: 0.014566\n",
      "Progresso: treinos: 1580, erro: 0.014078\n",
      "Progresso: treinos: 1600, erro: 0.016078\n",
      "Progresso: treinos: 1620, erro: 0.016384\n",
      "Progresso: treinos: 1640, erro: 0.016680\n",
      "Progresso: treinos: 1660, erro: 0.016919\n",
      "Progresso: treinos: 1680, erro: 0.014341\n",
      "Progresso: treinos: 1700, erro: 0.016195\n",
      "Progresso: treinos: 1720, erro: 0.016642\n",
      "Progresso: treinos: 1740, erro: 0.015554\n",
      "Progresso: treinos: 1760, erro: 0.016988\n",
      "Progresso: treinos: 1780, erro: 0.016957\n",
      "Progresso: treinos: 1800, erro: 0.014008\n",
      "Progresso: treinos: 1820, erro: 0.017282\n",
      "Progresso: treinos: 1840, erro: 0.015647\n",
      "Progresso: treinos: 1860, erro: 0.015798\n",
      "Progresso: treinos: 1880, erro: 0.014902\n",
      "Progresso: treinos: 1900, erro: 0.015459\n",
      "Progresso: treinos: 1920, erro: 0.016660\n",
      "Progresso: treinos: 1940, erro: 0.014847\n",
      "Progresso: treinos: 1960, erro: 0.016248\n",
      "Progresso: treinos: 1980, erro: 0.016259\n",
      "Progresso: treinos: 2000, erro: 0.013883\n",
      "\n",
      "Total de treinos: 2001\n",
      "            Erro: 0.014386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def treinar_rede(trainer, targetErr=0.01):\n",
    "    # Treinando a rede\n",
    "    treinos = 0\n",
    "    err = 10000\n",
    "    while err > targetErr:\n",
    "        err = trainer.train()\n",
    "        treinos += 1\n",
    "\n",
    "        #Exibir progresso a cada 100 iterações\n",
    "        if treinos % 20 == 0:\n",
    "            print \"Progresso: treinos: %d, erro: %f\" % (treinos, err)\n",
    "\n",
    "        if treinos > 1000:\n",
    "            break\n",
    "\n",
    "    print \"\\nTotal de treinos: %d\" % treinos\n",
    "    print \"            Erro: %f\\n\" % err\n",
    "    \n",
    "treinar_rede(trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[0, 1, 0]  ==  [0, 0, 1]  error!\n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 1, 0]  ==  [0, 0, 1]  error!\n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[0, 1, 0]  ==  [0, 0, 1]  error!\n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 1, 0]  ==  [0, 0, 1]  error!\n",
      "[0, 1, 0]  ==  [0, 0, 1]  error!\n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "\n",
      "Errors: 5 out of 38 (13.157895%)\n"
     ]
    }
   ],
   "source": [
    "def validar_dados(network, dataset, verbose=False):\n",
    "    errors = 0;\n",
    "    input = dataset.getField('input')\n",
    "    output = dataset.getField('target')\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        netw = [int(round(x)) for x in network.activate(input[i])]\n",
    "        expc = [x for x in output[i]]\n",
    "    \n",
    "        if (netw != expc):\n",
    "            errors += 1\n",
    "\n",
    "        if verbose:\n",
    "            print netw, \" == \", expc, \"%s\" % \"\" if netw == expc else \" error!\"\n",
    "\n",
    "    print \"\\nErrors: %d out of %d (%f%%)\" % (errors, len(dataset), float(errors) / len(dataset) * 100)\n",
    "\n",
    "validar_dados(network, TestDS, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP com dados originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 50, 1: 50, 2: 50}"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OriginalDS = generate_dataset(normalized_input, output_array)\n",
    "\n",
    "# Verificar que os dados estão como esperado\n",
    "OriginalDS.calculateStatistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OriginalDS._convertToOneOfMany()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino: 112, Teste: 38\n"
     ]
    }
   ],
   "source": [
    "OriginalTrainDS, OriginalTestDS = OriginalDS.splitWithProportion(0.75)\n",
    "print \"Treino: %d, Teste: %d\" % (len(OriginalTrainDS), len(OriginalTestDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network, trainer = criar_rede(OriginalTrainDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total de treinos: 9\n",
      "            Erro: 0.009180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "treinar_rede(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 0, 1]  ==  [0, 0, 1] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[0, 1, 0]  ==  [0, 1, 0] \n",
      "[1, 0, 0]  ==  [1, 0, 0] \n",
      "\n",
      "Errors: 0 out of 38 (0.000000%)\n"
     ]
    }
   ],
   "source": [
    "validar_dados(network, OriginalTestDS, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
